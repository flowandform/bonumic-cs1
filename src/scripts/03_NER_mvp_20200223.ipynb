{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.scorer import Scorer\n",
    "from spacy.gold import GoldParse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1)  Converting data from doccano jsonl annotation output\n",
    "\n",
    "def convert_doccano_to_spacy(filepath):\n",
    "    # opens the file as strings\n",
    "    with open(filepath, 'rb') as fp:\n",
    "        data = fp.readlines()\n",
    "        training_data = []\n",
    "    # converts the strings to json elements\n",
    "\n",
    "    for record in data:\n",
    "        entities = []\n",
    "        read_record = json.loads(record)\n",
    "\n",
    "        # gathers the text of the current element\n",
    "        text = read_record['text']\n",
    "        entities_record = read_record['labels']\n",
    "        # gathers the label of the curent element\n",
    "\n",
    "        # reshapes the labels to match the spacy format\n",
    "        for start, end, label in entities_record: \n",
    "            entities.append((start, end, label))\n",
    "        \n",
    "        # append the curent flyer information to the main appender lis\n",
    "        training_data.append((text, {'entities': entities}))\n",
    "        \n",
    "    \n",
    "    return training_data\n",
    "\n",
    "\n",
    "# 2) converting doccano outputs. Notice - sometimes pc will recognize it as .txt and sometimes as .json1, change the extension accordingly below\n",
    "NER_data_20200223 = convert_doccano_to_spacy(r'E:\\temporary_flownform_directory\\docano_output\\doccano_export_NER_20200223.txt')\n",
    "\n",
    "NER_data_20200209 = convert_doccano_to_spacy(r'E:\\temporary_flownform_directory\\docano_output\\doccano_export_NER_20200209.json1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NER_data_all = NER_data_20200223 + NER_data_20200209\n",
    "print(len(NER_data_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(NER_data_all)\n",
    "\n",
    "train_data = NER_data_all[0: int(len(NER_data_all)*0.8)]\n",
    "test_data = NER_data_all[int(len(NER_data_all)*0.8): len(NER_data_all)]\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train for demo purposes\n",
    "\n",
    "\n",
    "def train_spacy(data,iterations, model = None):\n",
    "    train_data = data\n",
    "    \n",
    "    # loading the model\n",
    "    if model is not None:\n",
    "        nlp = spacy.load(model)  # load existing spacy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        nlp = spacy.blank('en')  # train a blank model on top of thestandard en NER model\n",
    "        print(\"Created blank 'en' model\\n\")\n",
    "    \n",
    "    # if blank model is used we need to add the ner to the pipeline. Otherwise, get it with assumption it is called the same\n",
    "    # Ner will be only part of our pipeline\n",
    "    # common steps of the pipeline are \"pipeline\": [\"tagger\", \"parser\", \"ner\"]\n",
    "    # spacy will tokenize each word and apply the pipeline steps?\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe('ner')\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "    \n",
    "   # add labels to current ner\n",
    "    for _, annotations in train_data:\n",
    "        for ent in annotations.get('entities'):\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "#     # get names of other pipes to disable them during training\n",
    "#     pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "#     other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "#     with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "            \n",
    "    # starts the training and returns an optimizer function for updating the model weights\n",
    "    optimizer = nlp.begin_training()\n",
    "    \n",
    "    for itn in range(iterations):\n",
    "        counter = 0\n",
    "\n",
    "        print(\"\\nStatring iteration \" + str(itn))\n",
    "        \n",
    "        # raining data is shuffled to ensure the model doesn’t make any generalizations based on the order of examples\n",
    "        random.shuffle(train_data)\n",
    "        losses = {}\n",
    "        for text, entities in train_data:\n",
    "            counter += 1\n",
    "            print(\"processing text {}/{}\".format(counter, len(train_data)))\n",
    "# 1)            \n",
    "# SIMPLE TRAINING STYLE - sequence of raw texts and dictionaries of annotations\n",
    "#             nlp.update(\n",
    "#                 [text],  # batch of texts\n",
    "#                 [entities],  # batch of annotations\n",
    "#                 drop=0.2,  # dropout rate- makes it harder to memorise data. a rate at which to randomly “drop” individual features and representations. \n",
    "#                 sgd=optimizer,  # callable to update weights\n",
    "#                 losses=losses)\n",
    "\n",
    "# 2)\n",
    "# STANDARD SPACY TRAINING STYLE- sequence of Doc and GoldParse objects\n",
    "\n",
    "#             doc = nlp.make_doc(text)\n",
    "#             gold = GoldParse(doc, entities=entities['entities'])\n",
    "#             nlp.update(\n",
    "#                 [doc],  # batch of texts\n",
    "#                 [gold],  # batch of annotations\n",
    "#                 drop=0.2,  # dropout rate- makes it harder to memorise data. a rate at which to randomly “drop” individual features and representations. \n",
    "#                 sgd=optimizer,  # callable to update weights\n",
    "#                 losses=losses)\n",
    "            \n",
    "            \n",
    "            \n",
    "# 3) the minibatch (most optimal?) approach\n",
    "\n",
    "            batches = minibatch(train_data, size=compounding(4.0, 32.0, 1.001))\n",
    "\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp.update(\n",
    "                    texts,  # batch of texts\n",
    "                    annotations,  # batch of annotations\n",
    "                    drop=0.5,  # dropout - make it harder to memorise data\n",
    "                    losses=losses,\n",
    "                ) \n",
    "            \n",
    "        print(\"losses\", losses)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    return nlp\n",
    "\n",
    "\n",
    "subset_train_data = train_data[0:5]\n",
    "\n",
    "spacy_subset_demo_purposes = train_spacy(data = subset_train_data,\n",
    "            iterations= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation for demo purposes\n",
    "\n",
    "def evaluate(ner_model, examples):\n",
    "    scorer = Scorer()\n",
    "    for flyer in examples:\n",
    "        input_, annot = flyer\n",
    "        doc_gold_text = ner_model.make_doc(input_)\n",
    "        gold = GoldParse(doc_gold_text, entities=annot['entities'])\n",
    "        pred_value = ner_model(input_)\n",
    "        scorer.score(pred_value, gold)\n",
    "    return scorer.scores\n",
    "\n",
    "\n",
    "def custom_evaluation_script(annotated_test_data, ner_model, list_of_entities):\n",
    "    \n",
    "    \n",
    "    # 1) creating df from true labels from doccano annotators\n",
    "    true_df = pd.DataFrame(dict(('True_{}'.format(x),[]) for x in list_of_entities))\n",
    "                           \n",
    "    for text_and_entities in annotated_test_data:\n",
    "        temp_dict = dict(('True_{}'.format(x),[]) for x in list_of_entities)\n",
    "        text, entities = text_and_entities        \n",
    "        \n",
    "        for i in entities['entities']:\n",
    "            temp_dict['True_{}'.format(i[2])].append(text[i[0]:i[1]])\n",
    "            \n",
    "        true_df = true_df.append(temp_dict, ignore_index = True)\n",
    "        \n",
    "    \n",
    "    # 2) create df from recognized labels from trained NER model\n",
    "    NER_df = pd.DataFrame(dict(('NER_{}'.format(x),[]) for x in list_of_entities))\n",
    "    \n",
    "    text_for_extraction = [x[0] for x in annotated_test_data]\n",
    "    \n",
    "    for flyer_text in text_for_extraction:  \n",
    "        temp_dict = dict(('NER_{}'.format(x),[]) for x in list_of_entities)\n",
    "        doc = spacy_subset_demo_purposes(flyer_text)\n",
    "        \n",
    "        extracted_entity_label_tuples = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "        \n",
    "        for i in extracted_entity_label_tuples:\n",
    "            temp_dict['NER_{}'.format(i[1])].append(i[0])\n",
    "    \n",
    "        NER_df = NER_df.append(temp_dict, ignore_index = True)\n",
    "    \n",
    "    \n",
    "    # 3) use NER scorer for calculating metrics\n",
    "    ner_score_results = evaluate(ner_model, annotated_test_data)\n",
    "    \n",
    "    return true_df, NER_df, ner_score_results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "true, extracted, score_results = custom_evaluation_script(annotated_test_data = test_data,\n",
    "                        ner_model = spacy_subset_demo_purposes,\n",
    "                        list_of_entities = ['EMAIL',\n",
    "                                            'GPE (countries, cities, states)',\n",
    "                                            'PERSON',\n",
    "                                            'PRICING',\n",
    "                                            'SIZE',\n",
    "                                            'Street Adress',\n",
    "                                            'ZIP CODE'\n",
    "                                           ]\n",
    "                        )\n",
    "\n",
    "\n",
    "score_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def train_spacy(data,iterations, model = None):\n",
    "    train_data = data\n",
    "    \n",
    "    # loading the model\n",
    "    if model is not None:\n",
    "        nlp = spacy.load(model)  # load existing spacy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        nlp = spacy.blank('en')  # train a blank model on top of thestandard en NER model\n",
    "        print(\"Created blank 'en' model\\n\")\n",
    "    \n",
    "    # if blank model is used we need to add the ner to the pipeline. Otherwise, get it with assumption it is called the same\n",
    "    # Ner will be only part of our pipeline\n",
    "    # common steps of the pipeline are \"pipeline\": [\"tagger\", \"parser\", \"ner\"]\n",
    "    # spacy will tokenize each word and apply the pipeline steps?\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe('ner')\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "    \n",
    "   # add labels to current ner\n",
    "    for _, annotations in train_data:\n",
    "        for ent in annotations.get('entities'):\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "#     # get names of other pipes to disable them during training\n",
    "#     pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "#     other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "#     with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "            \n",
    "    # starts the training and returns an optimizer function for updating the model weights\n",
    "    optimizer = nlp.begin_training()\n",
    "    \n",
    "    for itn in range(iterations):\n",
    "        counter = 0\n",
    "\n",
    "        print(\"\\nStatring iteration \" + str(itn))\n",
    "        \n",
    "        # raining data is shuffled to ensure the model doesn’t make any generalizations based on the order of examples\n",
    "        random.shuffle(train_data)\n",
    "        losses = {}\n",
    "        for text, entities in train_data:\n",
    "            counter += 1\n",
    "            print(\"processing text {}/{}\".format(counter, len(train_data)))\n",
    "# 1)            \n",
    "# SIMPLE TRAINING STYLE - sequence of raw texts and dictionaries of annotations\n",
    "#             nlp.update(\n",
    "#                 [text],  # batch of texts\n",
    "#                 [entities],  # batch of annotations\n",
    "#                 drop=0.2,  # dropout rate- makes it harder to memorise data. a rate at which to randomly “drop” individual features and representations. \n",
    "#                 sgd=optimizer,  # callable to update weights\n",
    "#                 losses=losses)\n",
    "\n",
    "# 2)\n",
    "# STANDARD SPACY TRAINING STYLE- sequence of Doc and GoldParse objects\n",
    "\n",
    "#             doc = nlp.make_doc(text)\n",
    "#             gold = GoldParse(doc, entities=entities['entities'])\n",
    "#             nlp.update(\n",
    "#                 [doc],  # batch of texts\n",
    "#                 [gold],  # batch of annotations\n",
    "#                 drop=0.2,  # dropout rate- makes it harder to memorise data. a rate at which to randomly “drop” individual features and representations. \n",
    "#                 sgd=optimizer,  # callable to update weights\n",
    "#                 losses=losses)\n",
    "            \n",
    "            \n",
    "            \n",
    "# 3) the minibatch (most optimal?) approach\n",
    "\n",
    "            batches = minibatch(train_data, size=compounding(4.0, 32.0, 1.001))\n",
    "\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp.update(\n",
    "                    texts,  # batch of texts\n",
    "                    annotations,  # batch of annotations\n",
    "                    drop=0.5,  # dropout - make it harder to memorise data\n",
    "                    losses=losses,\n",
    "                ) \n",
    "            \n",
    "        print(\"losses\", losses)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    return nlp\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_train_data = train_data[0:5]\n",
    "\n",
    "spacy_subset_300_iterations_3 = train_spacy(data = subset_train_data,\n",
    "            iterations= 3)\n",
    "\n",
    "spacy_subset_all_train_iterations_3 = train_spacy(data = train_data,\n",
    "            iterations= 3)\n",
    "\n",
    "spacy_subset_all_train_iterations_6 = train_spacy(data = train_data,\n",
    "            iterations= 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_subset_all_train_iterations_6.to_disk(r'E:\\temporary_flownform_directory\\ner_output')\n",
    "spacy_subset_all_train_iterations_3.to_disk(r'E:\\temporary_flownform_directory\\ner_output')\n",
    "spacy_subset_300_iterations_3.to_disk(r'E:\\temporary_flownform_directory\\ner_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ner_model, examples):\n",
    "    scorer = Scorer()\n",
    "    for flyer in examples:\n",
    "        input_, annot = flyer\n",
    "        doc_gold_text = ner_model.make_doc(input_)\n",
    "        gold = GoldParse(doc_gold_text, entities=annot['entities'])\n",
    "        pred_value = ner_model(input_)\n",
    "        scorer.score(pred_value, gold)\n",
    "    return scorer.scores\n",
    "\n",
    "\n",
    "def custom_evaluation_script(annotated_test_data, ner_model, list_of_entities):\n",
    "    \n",
    "    \n",
    "    # 1) creating df from true labels from doccano annotators\n",
    "    true_df = pd.DataFrame(dict(('True_{}'.format(x),[]) for x in list_of_entities))\n",
    "                           \n",
    "    for text_and_entities in annotated_test_data:\n",
    "        temp_dict = dict(('True_{}'.format(x),[]) for x in list_of_entities)\n",
    "        text, entities = text_and_entities        \n",
    "        \n",
    "        for i in entities['entities']:\n",
    "            temp_dict['True_{}'.format(i[2])].append(text[i[0]:i[1]])\n",
    "            \n",
    "        true_df = true_df.append(temp_dict, ignore_index = True)\n",
    "        \n",
    "    \n",
    "    # 2) create df from recognized labels from trained NER model\n",
    "    NER_df = pd.DataFrame(dict(('NER_{}'.format(x),[]) for x in list_of_entities))\n",
    "    \n",
    "    text_for_extraction = [x[0] for x in annotated_test_data]\n",
    "    \n",
    "    for flyer_text in text_for_extraction:  \n",
    "        temp_dict = dict(('NER_{}'.format(x),[]) for x in list_of_entities)\n",
    "        doc = spacy_subset_all_train_iterations_6(flyer_text)\n",
    "        \n",
    "        extracted_entity_label_tuples = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "        \n",
    "        for i in extracted_entity_label_tuples:\n",
    "            temp_dict['NER_{}'.format(i[1])].append(i[0])\n",
    "    \n",
    "        NER_df = NER_df.append(temp_dict, ignore_index = True)\n",
    "    \n",
    "    \n",
    "    # 3) use NER scorer for calculating metrics\n",
    "    ner_score_results = evaluate(ner_model, annotated_test_data)\n",
    "    \n",
    "    return true_df, NER_df, ner_score_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true, extracted, score_results = custom_evaluation_script(annotated_test_data = test_data,\n",
    "                        ner_model = spacy_subset_all_train_iterations_6,\n",
    "                        list_of_entities = ['EMAIL',\n",
    "                                            'GPE (countries, cities, states)',\n",
    "                                            'PERSON',\n",
    "                                            'PRICING',\n",
    "                                            'SIZE',\n",
    "                                            'Street Adress',\n",
    "                                            'ZIP CODE'\n",
    "                                           ]\n",
    "                        )\n",
    "\n",
    "output_df = pd.concat([true,extracted], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true, extracted, score_results = custom_evaluation_script(annotated_test_data = test_data,\n",
    "                        ner_model = spacy_subset_all_train_iterations_3,\n",
    "                        list_of_entities = ['EMAIL',\n",
    "                                            'GPE (countries, cities, states)',\n",
    "                                            'PERSON',\n",
    "                                            'PRICING',\n",
    "                                            'SIZE',\n",
    "                                            'Street Adress',\n",
    "                                            'ZIP CODE'\n",
    "                                           ]\n",
    "                        )\n",
    "\n",
    "output_df = pd.concat([true,extracted], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true, extracted, score_results = custom_evaluation_script(annotated_test_data = test_data,\n",
    "                        ner_model = spacy_subset_300_iterations_3,\n",
    "                        list_of_entities = ['EMAIL',\n",
    "                                            'GPE (countries, cities, states)',\n",
    "                                            'PERSON',\n",
    "                                            'PRICING',\n",
    "                                            'SIZE',\n",
    "                                            'Street Adress',\n",
    "                                            'ZIP CODE'\n",
    "                                           ]\n",
    "                        )\n",
    "\n",
    "output_df = pd.concat([true,extracted], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
